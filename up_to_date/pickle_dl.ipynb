{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import numpy as np\n",
    "import os\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  유사도 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 폴더 경로\n",
    "folder_path = r\"\"\n",
    "\n",
    "# EfficientNet 모델 로드 및 임베딩 벡터 추출 레이어 설정\n",
    "base_model = models.efficientnet_b0(pretrained=True)\n",
    "base_model.classifier[1] = nn.Identity()  # Remove the classification layer\n",
    "\n",
    "# 이미지 전처리 함수\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((256, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def get_image_embedding(image_path, model, device):\n",
    "    try:\n",
    "        # 이미지 로드 및 전처리\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "\n",
    "        # 임베딩 벡터 생성\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            embedding_vector = model(img_tensor).cpu().numpy().flatten()\n",
    "        return embedding_vector\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"Cannot identify image file {image_path}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "def get_embeddings_from_folder(folder_path, model, device):\n",
    "    embeddings = []\n",
    "    image_paths = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(('jpg', 'jpeg', 'png')):\n",
    "            image_path = os.path.join(folder_path, file_name)\n",
    "            embedding = get_image_embedding(image_path, model, device)\n",
    "            if embedding is not None:\n",
    "                embeddings.append(embedding)\n",
    "                image_paths.append(image_path)\n",
    "    return np.array(embeddings), image_paths\n",
    "\n",
    "def plot_image_groups(groups):\n",
    "    for idx, group in enumerate(groups):\n",
    "        if idx < 200:\n",
    "            print(\"=================group {}=================\".format(idx))\n",
    "            plt.figure(figsize=(10,10))\n",
    "            for i, image_path in enumerate(group):\n",
    "                plt.subplot(1, len(group), i + 1)\n",
    "                img = Image.open(image_path)\n",
    "                plt.imshow(img)\n",
    "                plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "# 폴더 내 모든 이미지에 대한 임베딩 벡터 생성\n",
    "embeddings, image_paths = get_embeddings_from_folder(folder_path, base_model, device)\n",
    "\n",
    "# FAISS를 이용한 코사인 유사도 측정\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "faiss.normalize_L2(embeddings)\n",
    "index.add(embeddings)\n",
    "\n",
    "D, I = index.search(embeddings, k=len(embeddings))  # 모든 이미지에 대해 유사도 측정\n",
    "\n",
    "# 유사도 0.6 이상인 그룹 생성\n",
    "threshold = 0.775\n",
    "groups = []\n",
    "visited = set()\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    if i in visited:\n",
    "        continue\n",
    "    group = [image_paths[i]]\n",
    "    visited.add(i)\n",
    "    for j in range(1, len(I[i])):\n",
    "        if D[i][j] >= threshold and I[i][j] not in visited:\n",
    "            group.append(image_paths[I[i][j]])\n",
    "            visited.add(I[i][j])\n",
    "    groups.append(group)\n",
    "\n",
    "# 결과 출력\n",
    "print(device)\n",
    "plot_image_groups(groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. blurring 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model architecture\n",
    "class MobileNetClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MobileNetClassifier, self).__init__()\n",
    "        self.model = models.mobilenet_v2(pretrained=True)\n",
    "        self.model.classifier[1] = nn.Linear(self.model.last_channel, 2)  # Assuming 2 classes: blur and sharp\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "# Initialize your model\n",
    "blur_model = MobileNetClassifier()\n",
    "\n",
    "# mobilenet_centered_softblurred_scene_laplacian\n",
    "model_path = './mobilenet_blurred.pth'\n",
    "\n",
    "# Load the saved blur_model state_dict\n",
    "blur_model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# 이미지 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Device 설정 (GPU 또는 CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "blur_model.to(device)  # 모델을 GPU 또는 CPU로 전송\n",
    "\n",
    "def predict_blur(blur_model, image_path):\n",
    "    # 이미지 로드 및 전처리\n",
    "    image = Image.open(image_path).convert('RGB')  # RGB로 변환\n",
    "    image = transform(image).unsqueeze(0).to(device)  # 이미지를 GPU 또는 CPU로 전송\n",
    "\n",
    "    # 모델 예측\n",
    "    blur_model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = blur_model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "    # 결과 출력\n",
    "    classes = ['sharp','blur']\n",
    "    predicted_class = classes[predicted.item()]\n",
    "    if predicted_class == 'blur':\n",
    "        # blur 사진 테스트용 -> 바로 사진 print\n",
    "        # print(image_path)\n",
    "        # img = cv2.imread(image_path,cv2.IMREAD_ANYCOLOR)\n",
    "        # image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # plt.imshow(image_rgb)\n",
    "        # plt.axis('off')  # 축 제거\n",
    "        # plt.show()\n",
    "\n",
    "        # blur된 사진 경로 return\n",
    "        return image_path\n",
    "    elif predicted_class == 'sharp':\n",
    "        return None\n",
    "\n",
    "\n",
    "path = r\"C:\\Users\\ben81\\zflip_camera\"\n",
    "blurred_files = []\n",
    "\n",
    "for i in os.listdir(path):\n",
    "    if i.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(path, i)\n",
    "        try:\n",
    "            blurred_path = predict_blur(blur_model, image_path)\n",
    "            if blurred_path not None:\n",
    "                blurred_files.append(blurred_path)\n",
    "        except:\n",
    "            print('error')\n",
    "\n",
    "print(blurred_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Eye closing 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
