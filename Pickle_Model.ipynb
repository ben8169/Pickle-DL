{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle-DL 모델\n",
    "24/5/31 최종업뎃 <br>\n",
    "24/6/12 새 모델 시도 & 메타데이터\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNGRFZz0F1cg",
    "outputId": "c6f15615-90d1-4e21-bc26-eae33d82410b"
   },
   "outputs": [],
   "source": [
    "# !pip install torch torchvision\n",
    "# !pip install ftfy regex tqdm\n",
    "# !git clone https://github.com/openai/CLIP.git\n",
    "# !pip install git+https://github.com/openai/CLIP.git\n",
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. EfficientNet(B0) + faiss (0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ExifTags\n",
    "\n",
    "def correct_image_rotation(img):\n",
    "    try:\n",
    "        for orientation in ExifTags.TAGS.keys():\n",
    "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
    "                break\n",
    "\n",
    "        exif = img._getexif()\n",
    "        if exif is not None:\n",
    "            orientation = exif.get(orientation, None)\n",
    "\n",
    "            if orientation == 3:\n",
    "                img = img.rotate(180, expand=True)\n",
    "            elif orientation == 6:\n",
    "                img = img.rotate(270, expand=True)\n",
    "            elif orientation == 8:\n",
    "                img = img.rotate(90, expand=True)\n",
    "    except (AttributeError, KeyError, IndexError):\n",
    "        # In case of missing EXIF data or other issues, do nothing\n",
    "        pass\n",
    "\n",
    "    return img\n",
    "\n",
    "def get_image_embedding(image_path, model, device):\n",
    "    try:\n",
    "        # 이미지 로드 및 전처리\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img = correct_image_rotation(img)  # 이미지 회전 보정\n",
    "        img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "\n",
    "        # 임베딩 벡터 생성\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            embedding_vector = model(img_tensor).cpu().numpy().flatten()\n",
    "        return embedding_vector\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"Cannot identify image file {image_path}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "# 이미지 그룹 출력 시에도 회전 보정 적용\n",
    "def plot_image_groups(groups):\n",
    "    for idx, group in enumerate(groups):\n",
    "        if idx < 200:\n",
    "            print(\"=================group {}=================\".format(idx))\n",
    "            plt.figure(figsize=(10,10))\n",
    "            for i, image_path in enumerate(group):\n",
    "                plt.subplot(1, len(group), i + 1)\n",
    "                img = Image.open(image_path)\n",
    "                img = correct_image_rotation(img)  # 이미지 회전 보정\n",
    "                plt.imshow(img)\n",
    "                plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "# 예시 폴더 경로\n",
    "# folder_path = r\"C:\\Users\\ben81\\zflip_camera\"\n",
    "folder_path = r\"C:\\Users\\ben81\\zflip_random2\"\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "# 폴더 내 모든 이미지에 대한 임베딩 벡터 생성\n",
    "embeddings, image_paths = get_embeddings_from_folder(folder_path, base_model, device)\n",
    "\n",
    "# FAISS를 이용한 코사인 유사도 측정\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "faiss.normalize_L2(embeddings)\n",
    "index.add(embeddings)\n",
    "\n",
    "D, I = index.search(embeddings, k=len(embeddings))  # 모든 이미지에 대해 유사도 측정\n",
    "\n",
    "# 유사도 0.6 이상인 그룹 생성\n",
    "threshold = 0.65\n",
    "groups = []\n",
    "visited = set()\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    if i in visited:\n",
    "        continue\n",
    "    group = [image_paths[i]]\n",
    "    visited.add(i)\n",
    "    for j in range(1, len(I[i])):\n",
    "        if D[i][j] >= threshold and I[i][j] not in visited:\n",
    "            group.append(image_paths[I[i][j]])\n",
    "            visited.add(I[i][j])\n",
    "    groups.append(group)\n",
    "\n",
    "# 결과 출력\n",
    "print(device)\n",
    "plot_image_groups(groups)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32-1EaS2CotB",
    "outputId": "c86d314b-8c24-4ffa-c7d5-c50a5c2b5cfa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# CLIP 모델 로드\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# 이미지 파일들을 로드하고 전처리\n",
    "def load_images(image_folder):\n",
    "    images = []\n",
    "    image_files = [os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith(('png', 'jpg', 'jpeg'))]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image = preprocess(Image.open(image_file)).unsqueeze(0).to(device)\n",
    "        images.append((image_file, image))\n",
    "\n",
    "    return images\n",
    "\n",
    "# 이미지 임베딩 계산\n",
    "def get_image_features(images):\n",
    "    image_features = []\n",
    "    for image_file, image in images:\n",
    "        with torch.no_grad():\n",
    "            image_feature = model.encode_image(image)\n",
    "            image_features.append((image_file, image_feature))\n",
    "    return image_features\n",
    "\n",
    "# 텍스트 쿼리 임베딩 계산\n",
    "def get_text_features(text_query):\n",
    "    with torch.no_grad():\n",
    "        text_tokens = clip.tokenize([text_query]).to(device)\n",
    "        text_features = model.encode_text(text_tokens)\n",
    "    return text_features\n",
    "\n",
    "# 유사도 계산\n",
    "def calculate_similarity(image_features, text_features):\n",
    "    similarities = []\n",
    "    for image_file, image_feature in image_features:\n",
    "        similarity = torch.cosine_similarity(image_feature, text_features, dim=1)\n",
    "        similarities.append((image_file, similarity))\n",
    "    return similarities\n",
    "\n",
    "# 이미지 검색 함수\n",
    "def search_images(image_folder, text_query):\n",
    "    images = load_images(image_folder)\n",
    "    image_features = get_image_features(images)\n",
    "    text_features = get_text_features(text_query)\n",
    "    \n",
    "    similarities = calculate_similarity(image_features, text_features)\n",
    "    # Converting similarity scores to scalar for sorting\n",
    "    similarities = [(image_file, sim.item()) for image_file, sim in similarities]\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "# 해시태그 임베딩 계산\n",
    "def get_hashtag_features(hashtags):\n",
    "    with torch.no_grad():\n",
    "        text_tokens = clip.tokenize(hashtags).to(device)\n",
    "        text_features = model.encode_text(text_tokens)\n",
    "    return text_features\n",
    "\n",
    "# 해시태그 생성 함수\n",
    "def generate_hashtags(image_folder, hashtags):\n",
    "    images = load_images(image_folder)\n",
    "    image_features = get_image_features(images)\n",
    "    hashtag_features = get_hashtag_features(hashtags)\n",
    "\n",
    "    image_hashtags = {}\n",
    "    for image_file, image_feature in image_features:\n",
    "        similarity = torch.cosine_similarity(image_feature, hashtag_features, dim=1)\n",
    "        top_indices = similarity.topk(5).indices.cpu().numpy()\n",
    "        image_hashtags[image_file] = [hashtags[i] for i in top_indices]\n",
    "\n",
    "    return image_hashtags\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CLIP 이미지 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 폴더 경로 입력 \n",
    "image_folder = 'C:\\\\Users\\\\ben81\\\\GitHub\\\\Pickle-DL\\\\pickle_clip'\n",
    "# 텍스트 쿼리 설정\n",
    "text_query = \"travel image\"\n",
    "\n",
    "# 이미지 검색\n",
    "results = search_images(image_folder, text_query)\n",
    "\n",
    "# 결과 출력\n",
    "for image_file, similarity in results:\n",
    "    print(f\"Image: {image_file}, Similarity: {similarity}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. CLIP 해시태그 자동분배"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영어가 좀 더 작동 잘됨. 필요할 경우 한글 해시태그 영어로 번역해서 저장하는 것도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37dkvfuKNLYI",
    "outputId": "4b4cec12-7df5-4bf4-e52a-6a10403f043f"
   },
   "outputs": [],
   "source": [
    "# 이미지 폴더 경로\n",
    "image_folder = 'C:\\\\Users\\\\ben81\\\\GitHub\\\\Pickle-DL\\\\pickle_clip' \n",
    "\n",
    "# 해시태그 입력\n",
    "# hashtags = [\n",
    "#     \"#nature\", \"#travel\", \"#food\", \"#art\", \"#technology\",\n",
    "#     \"#fashion\", \"#sports\", \"#music\", \"#animals\", \"#people\"\n",
    "# ]\n",
    "hashtags = [\n",
    "    \"#character\", \"#people\", \"#travel\", \"#technology\", \"#art\",\n",
    "    \"#animals\", \"#computer\", \"#fashion\", \"#game\", \"#mobile\"\n",
    "]\n",
    "# hashtags = [\n",
    "#     \"#캐릭터\",\"#사람\",\"#여행\",\"#기술\",\"#예술\",\"#동물\",\"#컴퓨터\",\"#패션\", \"#게임\", \"#모바일\"\n",
    "# ]\n",
    "\n",
    "# 해시태그 생성\n",
    "image_hashtags = generate_hashtags(image_folder, hashtags)\n",
    "\n",
    "# 결과 출력\n",
    "for image_file, tags in image_hashtags.items():\n",
    "    print(f\"Image: {image_file}, Hashtags: {tags}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유사도 검색: CLIP + faiss (0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능이 매우별로다... threshold 줄이면 대참사가 난다.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import numpy as np\n",
    "import os\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "import clip\n",
    "\n",
    "# CLIP 모델 및 전처리기 로드\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "def get_image_embedding(image_path, model, preprocess, device):\n",
    "    try:\n",
    "        # 이미지 로드 및 전처리\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "\n",
    "        # 임베딩 벡터 생성\n",
    "        with torch.no_grad():\n",
    "            embedding_vector = model.encode_image(img_tensor).cpu().numpy().flatten()\n",
    "        return embedding_vector\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"Cannot identify image file {image_path}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "def get_embeddings_from_folder(folder_path, model, preprocess, device):\n",
    "    embeddings = []\n",
    "    image_paths = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(('jpg', 'jpeg', 'png')):\n",
    "            image_path = os.path.join(folder_path, file_name)\n",
    "            embedding = get_image_embedding(image_path, model, preprocess, device)\n",
    "            if embedding is not None:\n",
    "                embeddings.append(embedding)\n",
    "                image_paths.append(image_path)\n",
    "    return np.array(embeddings, dtype=np.float32), image_paths\n",
    "\n",
    "def plot_image_groups(groups):\n",
    "    for idx, group in enumerate(groups):\n",
    "        print(\"=================group {}=================\".format(idx))\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        for i, image_path in enumerate(group):\n",
    "            plt.subplot(1, len(group), i + 1)\n",
    "            img = Image.open(image_path)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# 폴더 경로\n",
    "folder_path = \"C:\\\\Users\\\\ben81\\\\GitHub\\\\Pickle-DL\\\\pickle\"\n",
    "\n",
    "# 폴더 내 모든 이미지에 대한 임베딩 벡터 생성\n",
    "embeddings, image_paths = get_embeddings_from_folder(folder_path, model, preprocess, device)\n",
    "\n",
    "# FAISS를 이용한 코사인 유사도 측정\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "faiss.normalize_L2(embeddings)\n",
    "index.add(embeddings)\n",
    "\n",
    "D, I = index.search(embeddings, k=len(embeddings))  # 모든 이미지에 대해 유사도 측정\n",
    "\n",
    "threshold = 0.8\n",
    "groups = []\n",
    "visited = set()\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    if i in visited:\n",
    "        continue\n",
    "    group = [image_paths[i]]\n",
    "    visited.add(i)\n",
    "    for j in range(1, len(I[i])):\n",
    "        if D[i][j] >= threshold and I[i][j] not in visited:\n",
    "            group.append(image_paths[I[i][j]])\n",
    "            visited.add(I[i][j])\n",
    "    groups.append(group)\n",
    "\n",
    "# 결과 출력\n",
    "plot_image_groups(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 새로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import torchvision.datasets as datasets\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Pretrained EfficientNet-B0 모델 불러오기\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "# 마지막 fully connected layer를 제거\n",
    "model.classifier = nn.Identity()\n",
    "\n",
    "# 이미지 전처리 함수 정의\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((256,224)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "class RotationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, transform):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = os.listdir(root_dir)  # 디렉토리에서 이미지 파일 경로 가져오기\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_paths[idx]\n",
    "        image_path = os.path.join(self.root_dir, image_name)  # 이미지 파일 경로 생성\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "\n",
    "        # 이미지를 무작위로 0도, 90도, 180도, 270도 회전\n",
    "        angle = random.choice([0, 90, 180, 270])\n",
    "        rotated_image = transforms.functional.rotate(image, angle)\n",
    "\n",
    "        return image, rotated_image\n",
    "\n",
    "\n",
    "# 데이터셋과 데이터로더 생성\n",
    "train_data = RotationDataset(root_dir=r\"C:\\Users\\ben81\\zflip_random1\", transform=preprocess)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "# 손실 함수 정의\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 옵티마이저 정의\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, rotated_images in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 모델에 이미지 전달하여 임베딩 얻기\n",
    "        embeddings = model(images)\n",
    "        rotated_embeddings = model(rotated_images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(embeddings, rotated_embeddings)\n",
    "\n",
    "        # 역전파 및 가중치 업데이트\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 모델 저장\n",
    "torch.save(model.state_dict(), 'model_weights.pth')\n",
    "\n",
    "# 모델 전체 저장 (모델 아키텍처 + 가중치)\n",
    "# torch.save(model, 'full_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import numpy as np\n",
    "import os\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# EfficientNet 모델 로드 및 임베딩 벡터 추출 레이어 설정\n",
    "base_model = models.efficientnet_b0(pretrained=False)\n",
    "base_model.classifier = nn.Identity()  # Remove the classification layer\n",
    "# base_model.load_state_dict(torch.load('model_weights.pth'))\n",
    "# base_model.eval()\n",
    "# 이미지 전처리 함수\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((256, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def get_image_embedding(image_path, model, device):\n",
    "    try:\n",
    "        # 이미지 로드 및 전처리\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "\n",
    "        # 임베딩 벡터 생성\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            embedding_vector = model(img_tensor).cpu().numpy().flatten()\n",
    "        return embedding_vector\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"Cannot identify image file {image_path}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "def get_embeddings_from_folder(folder_path, model, device):\n",
    "    embeddings = []\n",
    "    image_paths = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(('jpg', 'jpeg', 'png')):\n",
    "            image_path = os.path.join(folder_path, file_name)\n",
    "            embedding = get_image_embedding(image_path, model, device)\n",
    "            if embedding is not None:\n",
    "                embeddings.append(embedding)\n",
    "                image_paths.append(image_path)\n",
    "    return np.array(embeddings), image_paths\n",
    "\n",
    "def plot_image_groups(groups):\n",
    "    for idx, group in enumerate(groups):\n",
    "        if idx < 200:\n",
    "            print(\"=================group {}=================\".format(idx))\n",
    "            plt.figure(figsize=(20, 20))\n",
    "            for i, image_path in enumerate(group):\n",
    "                plt.subplot(1, len(group), i + 1)\n",
    "                img = Image.open(image_path)\n",
    "                plt.imshow(img)\n",
    "                plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "# 예시 폴더 경로\n",
    "folder_path = r\"C:\\Users\\ben81\\zflip_random2\"\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "# 폴더 내 모든 이미지에 대한 임베딩 벡터 생성\n",
    "embeddings, image_paths = get_embeddings_from_folder(folder_path, base_model, device)\n",
    "\n",
    "# FAISS를 이용한 코사인 유사도 측정\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "faiss.normalize_L2(embeddings)\n",
    "index.add(embeddings)\n",
    "\n",
    "D, I = index.search(embeddings, k=len(embeddings))  # 모든 이미지에 대해 유사도 측정\n",
    "\n",
    "# 유사도 0.6 이상인 그룹 생성\n",
    "threshold = 0.65\n",
    "groups = []\n",
    "visited = set()\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    if i in visited:\n",
    "        continue\n",
    "    group = [image_paths[i]]\n",
    "    visited.add(i)\n",
    "    for j in range(1, len(I[i])):\n",
    "        if D[i][j] >= threshold and I[i][j] not in visited:\n",
    "            group.append(image_paths[I[i][j]])\n",
    "            visited.add(I[i][j])\n",
    "    groups.append(group)\n",
    "\n",
    "# 결과 출력\n",
    "print(device)\n",
    "plot_image_groups(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import numpy as np\n",
    "import os\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# EfficientNet 모델 로드 및 임베딩 벡터 추출 레이어 설정\n",
    "base_model = models.efficientnet_b0(pretrained=False)\n",
    "base_model.classifier = nn.Identity()  # Remove the classification layer\n",
    "base_model.load_state_dict(torch.load('model_weights.pth'))\n",
    "base_model.eval()\n",
    "\n",
    "# 이미지 전처리 함수\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((256, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def get_orientation(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    points = np.argwhere(edges > 0)\n",
    "    points = np.fliplr(points)\n",
    "    mean, eigenvectors = cv2.PCACompute(points.astype(np.float32), mean=np.array([]))\n",
    "    angle = np.arctan2(eigenvectors[0, 1], eigenvectors[0, 0])\n",
    "    angle = np.degrees(angle)\n",
    "    return angle\n",
    "\n",
    "def align_image(image, angle):\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "def get_image_embedding(image_path, model, device):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "        angle = get_orientation(img_cv)\n",
    "        aligned_img_cv = align_image(img_cv, -angle)\n",
    "        aligned_img = Image.fromarray(cv2.cvtColor(aligned_img_cv, cv2.COLOR_BGR2RGB))\n",
    "        img_tensor = preprocess(aligned_img).unsqueeze(0).to(device)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            embedding_vector = model(img_tensor).cpu().numpy().flatten()\n",
    "        return embedding_vector\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"Cannot identify image file {image_path}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "def get_embeddings_from_folder(folder_path, model, device):\n",
    "    embeddings = []\n",
    "    image_paths = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(('jpg', 'jpeg', 'png')):\n",
    "            image_path = os.path.join(folder_path, file_name)\n",
    "            embedding = get_image_embedding(image_path, model, device)\n",
    "            if embedding is not None:\n",
    "                embeddings.append(embedding)\n",
    "                image_paths.append(image_path)\n",
    "    return np.array(embeddings), image_paths\n",
    "\n",
    "def plot_image_groups(groups):\n",
    "    for idx, group in enumerate(groups):\n",
    "        if idx < 200:\n",
    "            print(\"=================group {}=================\".format(idx))\n",
    "            plt.figure(figsize=(20, 20))\n",
    "            for i, image_path in enumerate(group):\n",
    "                plt.subplot(1, len(group), i + 1)\n",
    "                img = Image.open(image_path)\n",
    "                plt.imshow(img)\n",
    "                plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "# 예시 폴더 경로\n",
    "folder_path = r\"C:\\Users\\ben81\\zflip_camera\"\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "# 폴더 내 모든 이미지에 대한 임베딩 벡터 생성\n",
    "embeddings, image_paths = get_embeddings_from_folder(folder_path, base_model, device)\n",
    "\n",
    "# FAISS를 이용한 코사인 유사도 측정\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "faiss.normalize_L2(embeddings)\n",
    "index.add(embeddings)\n",
    "\n",
    "D, I = index.search(embeddings, k=len(embeddings))  # 모든 이미지에 대해 유사도 측정\n",
    "\n",
    "# 유사도 0.6 이상인 그룹 생성\n",
    "threshold = 0.65\n",
    "groups = []\n",
    "visited = set()\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    if i in visited:\n",
    "        continue\n",
    "    group = [image_paths[i]]\n",
    "    visited.add(i)\n",
    "    for j in range(1, len(I[i])):\n",
    "        if D[i][j] >= threshold and I[i][j] not in visited:\n",
    "            group.append(image_paths[I[i][j]])\n",
    "            visited.add(I[i][j])\n",
    "    if len(group) == 1:\n",
    "        img = cv2.imread(group[0])  # 이미지 읽기\n",
    "        rotated_embeddings = []\n",
    "        for angle in [0, 90, 180, 270]:  # 0, 90, 180, 270도로 회전\n",
    "            rotated_img = cv2.rotate(img, angle)\n",
    "            rotated_embedding = get_embeddings_from_folder(rotated_img, base_model, device)\n",
    "            rotated_embeddings.append(rotated_embedding)\n",
    "        rotated_embeddings = torch.cat(rotated_embeddings, dim=0)  # 회전된 임베딩 결합\n",
    "        rotated_D, rotated_I = index.search(rotated_embeddings, k=len(rotated_embeddings))  # 회전된 이미지에 대한 유사도 계산\n",
    "\n",
    "        # 회전된 이미지에서 가장 가까운 이미지를 찾아 해당 그룹에 추가\n",
    "        min_dist_idx = rotated_I[0][1]  # 첫 번째는 자기 자신이므로 두 번째로 가까운 이미지 선택\n",
    "        group.append(image_paths[min_dist_idx])\n",
    "\n",
    "        visited.add(min_dist_idx)\n",
    "\n",
    "    groups.append(group)\n",
    "\n",
    "# 결과 출력\n",
    "print(device)\n",
    "plot_image_groups(groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ExifTags\n",
    "\n",
    "def print_exif_data(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    exif_data = img._getexif()\n",
    "    if exif_data is not None:\n",
    "        for tag, value in exif_data.items():\n",
    "            tag_name = ExifTags.TAGS.get(tag, tag)\n",
    "            print(f\"{tag_name}: {value}\")\n",
    "    else:\n",
    "        print(\"No EXIF data found\")\n",
    "\n",
    "# 예시 이미지 경로\n",
    "image_path =r\"C:\\Users\\ben81\\zflip_random2\\20230809_185725.jpg\"\n",
    "print_exif_data(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
